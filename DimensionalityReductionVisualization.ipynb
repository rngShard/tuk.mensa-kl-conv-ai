{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring User Clustering Representations \n",
    "\n",
    "This exploration's goal is to grasp not necessarily how the provided user-rating-data is distributed (average number of ratings per user, number of users with more than 10 ratings etc.) but how expressive these are concerning actual user profiling.\n",
    "\n",
    "This is done by preparing a user-food-matrix and applying dimensionality reduction on them to see how well these separate in low-dimensional (2D) space.\n",
    "\n",
    "## General preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# constants\n",
    "MEAL_CSV = 'data/meal_manually_cleaned.csv'\n",
    "RATING_CSV = 'data/rating.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.normalizer.food_title_normalizer import FoodNormalizer\n",
    "\n",
    "df_ratings = pd.read_csv(RATING_CSV)\n",
    "\n",
    "normalizer = FoodNormalizer('../../'+MEAL_CSV)    # takes relative path from view of normalizer class as arg ...\n",
    "normalizer.assign_norm_titles()\n",
    "\n",
    "# normalizer.meal_df.head()\n",
    "# df_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we merge the normalizer (primary) title with the rating matrix - essentially looking up `m_id` - to see what meals the ratings actually belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalizer.meal_df\n",
    "df_ratings = df_ratings.assign(\n",
    "    title_prim=[df.loc[(df['m_id']==m_id),'title_prim'].to_string(index=False) \n",
    "                for m_id in df_ratings.loc[:,'m_id']])\n",
    "\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building up Sparse Matrix\n",
    "\n",
    "Now build up a (pretty _sparse_ ...) user-(primary)meal-matrix across all (primary) meal titles where for each user its ratings are entered at the corresponding position.\n",
    "\n",
    "Note: Users may have rated food at different times where the food with primary title is the same. These ratings are averaged and entered as a single rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_rating(ratings, food_title):\n",
    "    \"\"\"Searches for the food in a user's rating dict `{'rating':[...],'title_prim':[...]}`.\n",
    "    \n",
    "    This account for multiple ratings for meals having the same title_prim by taking the average\n",
    "    over all respective ratings.\n",
    "    \"\"\"\n",
    "    rating, n = 0, 0\n",
    "    for r in ratings:\n",
    "        if r['title_prim'] == food_title:\n",
    "            rating += r['rating']\n",
    "            n += 1\n",
    "    return rating / n\n",
    "\n",
    "title_prim_header = sorted(list(set(df_ratings.loc[:,'title_prim'])))\n",
    "users = sorted(set(df_ratings.loc[:,'user']))\n",
    "\n",
    "user_food_ratings_matrix, user_food_ratings_matrix_meaned = [], []\n",
    "for usr in users:\n",
    "    user_foods_rated = df_ratings.loc[(df_ratings['user']==usr),['title_prim','rating']].to_dict('records')\n",
    "    user_foods = set([food_rated['title_prim'] for food_rated in user_foods_rated])    # true subset of title_prim_header\n",
    "    food_rating_vector = [0 if food not in user_foods else get_rating(user_foods_rated, food) \n",
    "                          for food in title_prim_header]\n",
    "    user_food_ratings_matrix_meaned.append(food_rating_vector)\n",
    "    food_rating_vector_meaned = [2.5 if food not in user_foods else get_rating(user_foods_rated, food) \n",
    "                                 for food in title_prim_header]\n",
    "    user_food_ratings_matrix.append(food_rating_vector)\n",
    "df_user_food_ratings_matrix = pd.DataFrame(user_food_ratings_matrix, index=users, columns=title_prim_header)\n",
    "df_user_food_ratings_matrix_meaned = pd.DataFrame(user_food_ratings_matrix_meaned, index=users, columns=title_prim_header)\n",
    "    \n",
    "# df_user_food_ratings_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now obtained a __#users by #uniquePrimaryMeals__ -matrix.\n",
    "\n",
    "## Dim. Red. and Visualization\n",
    "\n",
    "Next, we standardize the matrix values and apply PCA to see some first results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ANNOTATE_THRESH_NUM = 10\n",
    "\n",
    "\"\"\"Preprocessing\"\"\"\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# vals = df_user_food_ratings_matrix.values\n",
    "# x = StandardScaler().fit_transform(vals)\n",
    "\n",
    "# # pd.DataFrame(x)\n",
    "\n",
    "X_names = ['User ratings missing filled with 0s', 'User ratings missing filled with 2.5s']\n",
    "X_all = df_user_food_ratings_matrix.values, df_user_food_ratings_matrix_meaned.values\n",
    "users_num_ratings = [np.sum([1 if r != 0 else 0 for r in user_ratings]) \n",
    "                     for user_ratings in user_food_ratings_matrix]\n",
    "# print(users_num_ratings)\n",
    "\n",
    "\"\"\"Dimensionality-reduction to 2D.\"\"\"\n",
    "\n",
    "dfs = []\n",
    "for i, X in enumerate(X_all):\n",
    "    dfs_X = []\n",
    "    pca = PCA(n_components=2)\n",
    "    dfs_X.append({'title': 'PCA, n=2',\n",
    "                  'df': pd.DataFrame(pca.fit_transform(X), columns=['c1', 'c2'])})\n",
    "    tsne = TSNE(n_components=2, perplexity=3)\n",
    "    dfs_X.append({'title': 't-SNE, n=2, perp=3',\n",
    "                  'df': pd.DataFrame(tsne.fit_transform(X), columns=['c1', 'c2'])})\n",
    "    tsne = TSNE(n_components=2, perplexity=5)\n",
    "    dfs_X.append({'title': 't-SNE, n=2, perp=5',\n",
    "                  'df': pd.DataFrame(tsne.fit_transform(X), columns=['c1', 'c2'])})\n",
    "    tsne = TSNE(n_components=2, perplexity=10)\n",
    "    dfs_X.append({'title': 't-SNE, n=2, perp=10',\n",
    "                  'df': pd.DataFrame(tsne.fit_transform(X), columns=['c1', 'c2'])})\n",
    "    dfs.append(dfs_X)\n",
    "\n",
    "\"\"\"Visualization.\"\"\"\n",
    "\n",
    "fig = plt.figure(figsize = (16,12))\n",
    "\n",
    "for i, dfs_X in enumerate(dfs):\n",
    "    print('Row {}: \"{}\"'.format(i+1, X_names[i]))\n",
    "    for j, df_type in enumerate(dfs_X):\n",
    "        ax = plt.subplot(len(dfs), len(dfs_X), i*len(dfs_X)+j+1)\n",
    "#         ax = plt.subplot(1, 2, 1)\n",
    "#         ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "#         ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "        ax.set_title(df_type['title'], fontsize = 25)\n",
    "        ax.grid()\n",
    "        scatter = ax.scatter(df_type['df'].loc[:, 'c1'], \n",
    "                             df_type['df'].loc[:, 'c2'],\n",
    "                             s = 50)\n",
    "        for k,r in enumerate(users_num_ratings):\n",
    "            if r > ANNOTATE_THRESH_NUM:\n",
    "                ax.annotate('User {0} ({1} ratings)'.format(k,r),\n",
    "                            (df_type['df'].loc[k, 'c1'], df_type['df'].loc[k, 'c2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that PCA scaptures points with a _representative enough_ number of ratings towards the outside compared to the cluster of few-rating-users, where there is a dendency towards different directions for different users.\n",
    "\n",
    "T-SNE on the other hand maximizes difference between different more-rating-users as it places them outside a cluster of similarly distributed few-rating-users. This intuitively makes sense at t-SNE aims to map distances in high-dim. space as closely as possible to distance in low-dim. space (frequently modeled as ith _springs_). This positions the only in a single dim. differing samples mostly uniformly in the inside and then stochastically distributes more complex positionde points outside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying setting unknwn values to `2.5` instead of `0`:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
